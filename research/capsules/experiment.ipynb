{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Framework for training and evaluating models.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from input_data.cifar10 import cifar10_input\n",
    "from input_data.mnist import mnist_input_record\n",
    "from input_data.norb import norb_input_record\n",
    "from models import capsule_model\n",
    "from models import conv_model\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "tf.flags.DEFINE_string('data_dir', None, 'The data directory.')\n",
    "tf.flags.DEFINE_integer('eval_size', 10000, 'Size of the test dataset.')\n",
    "tf.flags.DEFINE_string('hparams_override', None,\n",
    "                       'A string of form key=value,key=value to override the'\n",
    "                       'hparams of this experiment.')\n",
    "tf.flags.DEFINE_integer('max_steps', 1000, 'Number of steps to train.')\n",
    "tf.flags.DEFINE_string('model', 'capsule',\n",
    "                       'The model to use for the experiment.'\n",
    "                       'capsule or baseline')\n",
    "tf.flags.DEFINE_string('dataset', 'mnist',\n",
    "                       'The dataset to use for the experiment.'\n",
    "                       'mnist, norb, cifar10.')\n",
    "tf.flags.DEFINE_integer('num_gpus', 1, 'Number of gpus to use.')\n",
    "tf.flags.DEFINE_integer('num_targets', 1,\n",
    "                        'Number of targets to detect (1 or 2).')\n",
    "tf.flags.DEFINE_integer('num_trials', 1,\n",
    "                        'Number of trials for ensemble evaluation.')\n",
    "tf.flags.DEFINE_integer('save_step', 1500, 'How often to save checkpoints.')\n",
    "tf.flags.DEFINE_string('summary_dir', None,\n",
    "                       'Main directory for the experiments.')\n",
    "tf.flags.DEFINE_string('checkpoint', None,\n",
    "                       'The model checkpoint for evaluation.')\n",
    "tf.flags.DEFINE_bool('train', True, 'Either train the model or test the model.')\n",
    "tf.flags.DEFINE_bool('validate', False, 'Run trianing/eval in validation mode.')\n",
    "\n",
    "models = {\n",
    "    'capsule': capsule_model.CapsuleModel,\n",
    "    'baseline': conv_model.ConvModel,\n",
    "}\n",
    "\n",
    "\n",
    "def get_features(split, total_batch_size, num_gpus, data_dir, num_targets,\n",
    "                 dataset, validate=False):\n",
    "  \"\"\"Reads the input data and distributes it over num_gpus GPUs.\n",
    "  Each tower of data has 1/FLAGS.num_gpus of the total_batch_size.\n",
    "  Args:\n",
    "    split: 'train' or 'test', split of the data to read.\n",
    "    total_batch_size: total number of data entries over all towers.\n",
    "    num_gpus: Number of GPUs to distribute the data on.\n",
    "    data_dir: Directory containing the input data.\n",
    "    num_targets: Number of objects present in the image.\n",
    "    dataset: The name of the dataset, either norb or mnist.\n",
    "    validate: If set, subset training data into training and test.\n",
    "  Returns:\n",
    "    A list of batched feature dictionaries.\n",
    "  Raises:\n",
    "    ValueError: If dataset is not mnist or norb.\n",
    "  \"\"\"\n",
    "\n",
    "  batch_size = total_batch_size // max(1, num_gpus)\n",
    "  features = []\n",
    "  for i in range(num_gpus):\n",
    "    with tf.device('/gpu:%d' % i):\n",
    "      if dataset == 'mnist':\n",
    "        features.append(\n",
    "            mnist_input_record.inputs(\n",
    "                data_dir=data_dir,\n",
    "                batch_size=batch_size,\n",
    "                split=split,\n",
    "                num_targets=num_targets,\n",
    "                validate=validate,\n",
    "            ))\n",
    "      elif dataset == 'norb':\n",
    "        features.append(\n",
    "            norb_input_record.inputs(\n",
    "                data_dir=data_dir, batch_size=batch_size, split=split,\n",
    "            ))\n",
    "      elif dataset == 'cifar10':\n",
    "        data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\n",
    "        features.append(\n",
    "            cifar10_input.inputs(\n",
    "                split=split, data_dir=data_dir, batch_size=batch_size))\n",
    "      else:\n",
    "        raise ValueError(\n",
    "            'Unexpected dataset {!r}, must be mnist, norb, or cifar10.'.format(\n",
    "                dataset))\n",
    "  return features\n",
    "\n",
    "\n",
    "def extract_step(path):\n",
    "  \"\"\"Returns the step from the file format name of Tensorflow checkpoints.\n",
    "  Args:\n",
    "    path: The checkpoint path returned by tf.train.get_checkpoint_state.\n",
    "      The format is: {ckpnt_name}-{step}\n",
    "  Returns:\n",
    "    The last training step number of the checkpoint.\n",
    "  \"\"\"\n",
    "  file_name = os.path.basename(path)\n",
    "  return int(file_name.split('-')[-1])\n",
    "\n",
    "\n",
    "def load_training(saver, session, load_dir):\n",
    "  \"\"\"Loads a saved model into current session or initializes the directory.\n",
    "  If there is no functioning saved model or FLAGS.restart is set, cleans the\n",
    "  load_dir directory. Otherwise, loads the latest saved checkpoint in load_dir\n",
    "  to session.\n",
    "  Args:\n",
    "    saver: An instance of tf.train.saver to load the model in to the session.\n",
    "    session: An instance of tf.Session with the built-in model graph.\n",
    "    load_dir: The directory which is used to load the latest checkpoint.\n",
    "  Returns:\n",
    "    The latest saved step.\n",
    "  \"\"\"\n",
    "  if tf.gfile.Exists(load_dir):\n",
    "    ckpt = tf.train.get_checkpoint_state(load_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      saver.restore(session, ckpt.model_checkpoint_path)\n",
    "      prev_step = extract_step(ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "      tf.gfile.DeleteRecursively(load_dir)\n",
    "      tf.gfile.MakeDirs(load_dir)\n",
    "      prev_step = 0\n",
    "  else:\n",
    "    tf.gfile.MakeDirs(load_dir)\n",
    "    prev_step = 0\n",
    "  return prev_step\n",
    "\n",
    "\n",
    "def train_experiment(session, result, writer, last_step, max_steps, saver,\n",
    "                     summary_dir, save_step):\n",
    "  \"\"\"Runs training for up to max_steps and saves the model and summaries.\n",
    "  Args:\n",
    "    session: The loaded tf.session with the initialized model.\n",
    "    result: The resultant operations of the model including train_op.\n",
    "    writer: The summary writer file.\n",
    "    last_step: The last trained step.\n",
    "    max_steps: Maximum number of training iterations.\n",
    "    saver: An instance of tf.train.saver to save the current model.\n",
    "    summary_dir: The directory to save the model in it.\n",
    "    save_step: How often to save the model ckpt.\n",
    "  \"\"\"\n",
    "  step = 0\n",
    "  for i in range(last_step, max_steps):\n",
    "    step += 1\n",
    "    summary, _ = session.run([result.summary, result.train_op])\n",
    "    writer.add_summary(summary, i)\n",
    "    if (i + 1) % save_step == 0:\n",
    "      saver.save(\n",
    "          session, os.path.join(summary_dir, 'model.ckpt'), global_step=i + 1)\n",
    "\n",
    "\n",
    "def load_eval(saver, session, load_dir):\n",
    "  \"\"\"Loads the latest saved model to the given session.\n",
    "  Args:\n",
    "    saver: An instance of tf.train.saver to load the model in to the session.\n",
    "    session: An instance of tf.Session with the built-in model graph.\n",
    "    load_dir: The path to the latest checkpoint.\n",
    "  Returns:\n",
    "    The latest saved step.\n",
    "  \"\"\"\n",
    "  saver.restore(session, load_dir)\n",
    "  print('model loaded successfully')\n",
    "  return extract_step(load_dir)\n",
    "\n",
    "\n",
    "def eval_experiment(session, result, writer, last_step, max_steps, **kwargs):\n",
    "  \"\"\"Evaluates the current model on the test dataset once.\n",
    "  Evaluates the loaded model on the test data set with batch sizes of 100.\n",
    "  Aggregates the results and writes one summary point to the summary file.\n",
    "  Args:\n",
    "    session: The loaded tf.session with the trained model.\n",
    "    result: The resultant operations of the model including evaluation metrics.\n",
    "    writer: The summary writer file.\n",
    "    last_step: The last trained step.\n",
    "    max_steps: Maximum number of evaluation iterations.\n",
    "    **kwargs: Arguments passed by run_experiment but not used in this function.\n",
    "  \"\"\"\n",
    "  del kwargs\n",
    "\n",
    "  total_correct = 0\n",
    "  total_almost = 0\n",
    "  for _ in range(max_steps):\n",
    "    summary_i, correct, almost = session.run(\n",
    "        [result.summary, result.correct, result.almost])\n",
    "    total_correct += correct\n",
    "    total_almost += almost\n",
    "\n",
    "  total_false = max_steps * 100 - total_correct\n",
    "  total_almost_false = max_steps * 100 - total_almost\n",
    "  summary = tf.Summary.FromString(summary_i)\n",
    "  summary.value.add(tag='correct_prediction', simple_value=total_correct)\n",
    "  summary.value.add(tag='wrong_prediction', simple_value=total_false)\n",
    "  summary.value.add(\n",
    "      tag='almost_wrong_prediction', simple_value=total_almost_false)\n",
    "  print('Total wrong predictions: {}, wrong percent: {}%'.format(\n",
    "      total_false, total_false / max_steps))\n",
    "  tf.logging.info('Total wrong predictions: {}, wrong percent: {}%'.format(\n",
    "      total_false, total_false / max_steps))\n",
    "  writer.add_summary(summary, last_step)\n",
    "\n",
    "\n",
    "def run_experiment(loader,\n",
    "                   load_dir,\n",
    "                   writer,\n",
    "                   experiment,\n",
    "                   result,\n",
    "                   max_steps,\n",
    "                   save_step=0):\n",
    "  \"\"\"Starts a session, loads the model and runs the given experiment on it.\n",
    "  This is a general wrapper to load a saved model and run an experiment on it.\n",
    "  An experiment can be a training experiment or an evaluation experiment.\n",
    "  It starts session, threads and queues and closes them before returning.\n",
    "  Args:\n",
    "    loader: A function of prototype (saver, session, load_dir) to load a saved\n",
    "      checkpoint in load_dir given a session and saver.\n",
    "    load_dir: The directory to load the previously saved model from it and to\n",
    "      save the current model in it.\n",
    "    writer: A tf.summary.FileWriter to add summaries.\n",
    "    experiment: The function of prototype (session, result, writer, last_step,\n",
    "      max_steps, saver, load_dir, save_step) which will execute the experiment\n",
    "      steps from result on the given session.\n",
    "    result: The resultant final operations of the built model.\n",
    "    max_steps: Maximum number of experiment iterations.\n",
    "    save_step: How often the training model should be saved.\n",
    "  \"\"\"\n",
    "  session = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "  init_op = tf.group(tf.global_variables_initializer(),\n",
    "                     tf.local_variables_initializer())\n",
    "  session.run(init_op)\n",
    "  saver = tf.train.Saver(max_to_keep=1000)\n",
    "  last_step = loader(saver, session, load_dir)\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
    "  try:\n",
    "    experiment(\n",
    "        session=session,\n",
    "        result=result,\n",
    "        writer=writer,\n",
    "        last_step=last_step,\n",
    "        max_steps=max_steps,\n",
    "        saver=saver,\n",
    "        summary_dir=load_dir,\n",
    "        save_step=save_step)\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    tf.logging.info('Finished experiment.')\n",
    "  finally:\n",
    "    coord.request_stop()\n",
    "  coord.join(threads)\n",
    "  session.close()\n",
    "\n",
    "\n",
    "def train(hparams, summary_dir, num_gpus, model_type, max_steps, save_step,\n",
    "          data_dir, num_targets, dataset, validate):\n",
    "  \"\"\"Trains a model with batch sizes of 128 to FLAGS.max_steps steps.\n",
    "  It will initialize the model with either previously saved model in the\n",
    "  summary directory or start from scratch if FLAGS.restart is set or the\n",
    "  directory is empty.\n",
    "  The training is distributed on num_gpus GPUs. It writes a summary at every\n",
    "  step and saves the model every 1500 iterations.\n",
    "  Args:\n",
    "    hparams: The hyper parameters to build the model graph.\n",
    "    summary_dir: The directory to save model and write training summaries.\n",
    "    num_gpus: Number of GPUs to use for reading data and computation.\n",
    "    model_type: The model architecture category.\n",
    "    max_steps: Maximum number of training iterations.\n",
    "    save_step: How often the training model should be saved.\n",
    "    data_dir: Directory containing the input data.\n",
    "    num_targets: Number of objects present in the image.\n",
    "    dataset: Name of the dataset for the experiments.\n",
    "    validate: If set, use training-validation set for training.\n",
    "  \"\"\"\n",
    "  summary_dir += '/train/'\n",
    "  with tf.Graph().as_default():\n",
    "    # Build model\n",
    "    features = get_features('train', 128, num_gpus, data_dir, num_targets,\n",
    "                            dataset, validate)\n",
    "    model = models[model_type](hparams)\n",
    "    result, _ = model.multi_gpu(features, num_gpus)\n",
    "    # Print stats\n",
    "    param_stats = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "        tf.get_default_graph(),\n",
    "        tfprof_options=tf.contrib.tfprof.model_analyzer.\n",
    "        TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
    "    sys.stdout.write('total_params: %d\\n' % param_stats.total_parameters)\n",
    "    writer = tf.summary.FileWriter(summary_dir)\n",
    "    run_experiment(load_training, summary_dir, writer, train_experiment, result,\n",
    "                   max_steps, save_step)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def find_checkpoint(load_dir, seen_step):\n",
    "  \"\"\"Finds the global step for the latest written checkpoint to the load_dir.\n",
    "  Args:\n",
    "    load_dir: The directory address to look for the training checkpoints.\n",
    "    seen_step: Latest step which evaluation has been done on it.\n",
    "  Returns:\n",
    "    The latest new step in the load_dir and the file path of the latest model\n",
    "    in load_dir. If no new file is found returns -1 and None.\n",
    "  \"\"\"\n",
    "  ckpt = tf.train.get_checkpoint_state(load_dir)\n",
    "  if ckpt and ckpt.model_checkpoint_path:\n",
    "    global_step = extract_step(ckpt.model_checkpoint_path)\n",
    "    if int(global_step) != seen_step:\n",
    "      return int(global_step), ckpt.model_checkpoint_path\n",
    "  return -1, None\n",
    "\n",
    "\n",
    "def evaluate(hparams, summary_dir, num_gpus, model_type, eval_size, data_dir,\n",
    "             num_targets, dataset, validate, checkpoint=None):\n",
    "  \"\"\"Continuously evaluates the latest trained model or a specific checkpoint.\n",
    "  Regularly (every 2 min, maximum 6 hours) checks the training directory for\n",
    "  the latest model. If it finds any new model, it outputs the total number of\n",
    "  correct and wrong predictions for the test data set to the summary file.\n",
    "  If a checkpoint is provided performs the evaluation only on the specific\n",
    "  checkpoint.\n",
    "  Args:\n",
    "    hparams: The hyperparameters for building the model graph.\n",
    "    summary_dir: The directory to load training model and write test summaries.\n",
    "    num_gpus: Number of GPUs to use for reading data and computation.\n",
    "    model_type: The model architecture category.\n",
    "    eval_size: Total number of examples in the test dataset.\n",
    "    data_dir: Directory containing the input data.\n",
    "    num_targets: Number of objects present in the image.\n",
    "    dataset: The name of the dataset for the experiment.\n",
    "    validate: If set, use validation set for continuous evaluation.\n",
    "    checkpoint: (optional) The checkpoint file name.\n",
    "  \"\"\"\n",
    "  load_dir = summary_dir + '/train/'\n",
    "  summary_dir += '/test/'\n",
    "  with tf.Graph().as_default():\n",
    "    features = get_features('test', 100, num_gpus, data_dir, num_targets,\n",
    "                            dataset, validate)\n",
    "    model = models[model_type](hparams)\n",
    "    result, _ = model.multi_gpu(features, num_gpus)\n",
    "    test_writer = tf.summary.FileWriter(summary_dir)\n",
    "    seen_step = -1\n",
    "    paused = 0\n",
    "    while paused < 360:\n",
    "      print('start evaluation, model defined')\n",
    "      if checkpoint:\n",
    "        step = extract_step(checkpoint)\n",
    "        last_checkpoint = checkpoint\n",
    "      else:\n",
    "        step, last_checkpoint = find_checkpoint(load_dir, seen_step)\n",
    "      if step == -1:\n",
    "        time.sleep(60)\n",
    "        paused += 1\n",
    "      else:\n",
    "        paused = 0\n",
    "        seen_step = step\n",
    "        run_experiment(load_eval, last_checkpoint, test_writer, eval_experiment,\n",
    "                       result, eval_size // 100)\n",
    "        if checkpoint:\n",
    "          break\n",
    "\n",
    "    test_writer.close()\n",
    "\n",
    "\n",
    "def get_placeholder_data(num_steps, batch_size, features, session):\n",
    "  \"\"\"Reads the features into a numpy array and replaces them with placeholders.\n",
    "  Loads all the images and labels of the features queue in memory. Replaces\n",
    "  the feature queue reader handle with placeholders to switch input method from\n",
    "  queue to placeholders. Using placeholders gaurantees the order of datapoints\n",
    "  to stay exactly the same during each epoch.\n",
    "  Args:\n",
    "    num_steps: The number of times to read from the features queue.\n",
    "    batch_size: The number of datapoints at each step.\n",
    "    features: The dictionary containing the data queues such as images.\n",
    "    session: The session handle to use for running tensors.\n",
    "  Returns:\n",
    "    data: List of numpy arrays containing all the queued data in features.\n",
    "    targets: List of all the labels in range [0...num_classes].\n",
    "  \"\"\"\n",
    "  image_size = features['height']\n",
    "  depth = features['depth']\n",
    "  num_classes = features['num_classes']\n",
    "  data = []\n",
    "  targets = []\n",
    "  for i in range(num_steps):\n",
    "    data.append(\n",
    "        session.run({\n",
    "            'recons_label': features['recons_label'],\n",
    "            'labels': features['labels'],\n",
    "            'images': features['images'],\n",
    "            'recons_image': features['recons_image']\n",
    "        }))\n",
    "    targets.append(data[i]['recons_label'])\n",
    "  image_shape = (batch_size, depth, image_size, image_size)\n",
    "  features['images'] = tf.placeholder(tf.float32, shape=image_shape)\n",
    "  features['labels'] = tf.placeholder(\n",
    "      tf.float32, shape=(batch_size, num_classes))\n",
    "  features['recons_image'] = tf.placeholder(tf.float32, shape=image_shape)\n",
    "  features['recons_label'] = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "  return data, targets\n",
    "\n",
    "\n",
    "def infer_ensemble_logits(features, model, checkpoints, session, num_steps,\n",
    "                          data):\n",
    "  \"\"\"Extracts the logits for the whole dataset and all the trained models.\n",
    "  Loads all the checkpoints. For each checkpoint stores the logits for the whole\n",
    "  dataset.\n",
    "  Args:\n",
    "    features: The dictionary of the input handles.\n",
    "    model: The model operation graph.\n",
    "    checkpoints: The list of all checkpoint paths.\n",
    "    session: The session handle to use for running tensors.\n",
    "    num_steps: The number of steps to run the experiment.\n",
    "    data: The num_steps list of loaded data to be fed to placeholders.\n",
    "  Returns:\n",
    "    logits: List of all the final layer logits for different checkpoints.\n",
    "  \"\"\"\n",
    "  _, inferred = model.multi_gpu([features], 1)\n",
    "  logits = []\n",
    "  saver = tf.train.Saver()\n",
    "  for checkpoint in checkpoints:\n",
    "    saver.restore(session, checkpoint)\n",
    "    for i in range(num_steps):\n",
    "      logits.append(\n",
    "          session.run(\n",
    "              inferred[0].logits,\n",
    "              feed_dict={\n",
    "                  features['recons_label']: data[i]['recons_label'],\n",
    "                  features['labels']: data[i]['labels'],\n",
    "                  features['images']: data[i]['images'],\n",
    "                  features['recons_image']: data[i]['recons_image']\n",
    "              }))\n",
    "  return logits\n",
    "\n",
    "\n",
    "def evaluate_ensemble(hparams, model_type, eval_size, data_dir, num_targets,\n",
    "                      dataset, checkpoint, num_trials):\n",
    "  \"\"\"Evaluates an ensemble of trained models.\n",
    "  Loads a series of checkpoints and aggregates the output logit of them on the\n",
    "  test data. Selects the class with maximum aggregated logit as the prediction.\n",
    "  Prints the total number of wrong predictions.\n",
    "  Args:\n",
    "    hparams: The hyperparameters for building the model graph.\n",
    "    model_type: The model architecture category.\n",
    "    eval_size: Total number of examples in the test dataset.\n",
    "    data_dir: Directory containing the input data.\n",
    "    num_targets: Number of objects present in the image.\n",
    "    dataset: The name of the dataset for the experiment.\n",
    "    checkpoint: The file format of the checkpoints to be loaded.\n",
    "    num_trials: Number of trained models to ensemble.\n",
    "  \"\"\"\n",
    "  checkpoints = []\n",
    "  for i in range(num_trials):\n",
    "    file_name = checkpoint.format(i)\n",
    "    if tf.train.checkpoint_exists(file_name):\n",
    "      checkpoints.append(file_name)\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    batch_size = 100\n",
    "    features = get_features('test', batch_size, 1, data_dir, num_targets,\n",
    "                            dataset)[0]\n",
    "    model = models[model_type](hparams)\n",
    "\n",
    "    session = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
    "    num_steps = eval_size // batch_size\n",
    "    data, targets = get_placeholder_data(num_steps, batch_size, features,\n",
    "                                         session)\n",
    "    logits = infer_ensemble_logits(features, model, checkpoints, session,\n",
    "                                   num_steps, data)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    session.close()\n",
    "\n",
    "    logits = np.reshape(logits, (num_trials, num_steps, batch_size, -1))\n",
    "    logits = np.sum(logits, axis=0)\n",
    "    predictions = np.argmax(logits, axis=2)\n",
    "    total_wrong = np.sum(np.not_equal(predictions, targets))\n",
    "    print('Total wrong predictions: {}, wrong percent: {}%'.format(\n",
    "        total_wrong, total_wrong / eval_size * 100))\n",
    "\n",
    "\n",
    "def default_hparams():\n",
    "  \"\"\"Builds an HParam object with default hyperparameters.\"\"\"\n",
    "  return tf.contrib.training.HParams(\n",
    "      decay_rate=0.96,\n",
    "      decay_steps=2000,\n",
    "      leaky=False,\n",
    "      learning_rate=0.001,\n",
    "      loss_type='margin',\n",
    "      num_prime_capsules=32,\n",
    "      padding='VALID',\n",
    "      remake=True,\n",
    "      routing=3,\n",
    "      verbose=False,\n",
    "  )\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  hparams = default_hparams()\n",
    "  if FLAGS.hparams_override:\n",
    "    hparams.parse(FLAGS.hparams_override)\n",
    "\n",
    "  if FLAGS.train:\n",
    "    train(hparams, FLAGS.summary_dir, FLAGS.num_gpus, FLAGS.model,\n",
    "          FLAGS.max_steps, FLAGS.save_step, FLAGS.data_dir, FLAGS.num_targets,\n",
    "          FLAGS.dataset, FLAGS.validate)\n",
    "  else:\n",
    "    if FLAGS.num_trials == 1:\n",
    "      evaluate(hparams, FLAGS.summary_dir, FLAGS.num_gpus, FLAGS.model,\n",
    "               FLAGS.eval_size, FLAGS.data_dir, FLAGS.num_targets,\n",
    "               FLAGS.dataset, FLAGS.validate, FLAGS.checkpoint)\n",
    "    else:\n",
    "      evaluate_ensemble(hparams, FLAGS.model, FLAGS.eval_size, FLAGS.data_dir,\n",
    "                        FLAGS.num_targets, FLAGS.dataset, FLAGS.checkpoint,\n",
    "                        FLAGS.num_trials)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
